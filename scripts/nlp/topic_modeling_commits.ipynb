{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Topic Modeling for Commits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pygsheets\n",
    "import pandas as pd\n",
    "import stanza\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import clear_output\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel, LsiModel, LdaModel, HdpModel\n",
    "from markdown import markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pre-processing and helper methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "STOPWORDS = STOPWORDS.union((\n",
    "    \"var\", \"variable\", \"computed\", \"costa\", \"botocore\", \"version\", \"step\",\n",
    "    \"support\", \"source\", \"hashicorp\", \"service\", \"branch\", \"pull\", \"merge\", \"issue\",\n",
    "    \"pr\", \"galoy-pay\", \"bumped\", \"add\", \"payload\", \"boto\", \"accurics\", \"hana\",\n",
    "    \"bump\", \"added\", \"latest\", \"update\", \"tf\", \"github\", \"test\", \"sourced\",\n",
    "    \"instead\", \"use\", \"plan\", \"updates\", \"diff\", \"bump-galoy-pay-image\", \"draft\",\n",
    "    \"iam\", \"i'm\", \"v1\", \"apply\", \"fix\", \"fixes\", \"kvo\", \"needed\", \"tco\", \"create\",\n",
    "    \"run\", \"code\", \"feat\", \"lambda\", \"need\", \"link\", \"project\", \"new\", \"change\",\n",
    "    \"they're\"\n",
    "))\n",
    "\n",
    "UPOS = ('PROPN', 'NOUN', 'VERB', 'ADJ', 'ADV')\n",
    "nlp_pipeline = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
    "\n",
    "def prepare_document(doc):\n",
    "    # Remove MarkDown and HTML\n",
    "    clean_doc = markdown(doc)\n",
    "    clean_doc = ''.join(BeautifulSoup(clean_doc).findAll(text=True))\n",
    "\n",
    "    tokens = [token.to_dict()[0][\"lemma\"]\n",
    "                for token in nlp_pipeline(clean_doc).iter_tokens()\n",
    "                if token.to_dict()[0][\"upos\"] in UPOS and not token.to_dict()[0][\"text\"] in STOPWORDS\n",
    "            ]\n",
    "    return tokens\n",
    "\n",
    "def prepare_corpus(documents):\n",
    "    corpus = []\n",
    "    total_docs = len(documents)\n",
    "\n",
    "    for i in range(total_docs):\n",
    "        print(f'{total_docs} documents: {(i+1)/total_docs*100:.2f}% parsed')\n",
    "        print(documents[i])\n",
    "        corpus.append(prepare_document(documents[i]))\n",
    "        clear_output(wait=False)\n",
    "\n",
    "    return corpus\n",
    "\n",
    "def build_tfidf_model(corpus):\n",
    "    corpus_dict = Dictionary(corpus)\n",
    "    corpus_bow = tuple(corpus_dict.doc2bow(sentence) for sentence in corpus)\n",
    "    tfidf_model = TfidfModel(corpus_bow, normalize=True)\n",
    "\n",
    "    return corpus_dict, corpus_bow, tfidf_model\n",
    "\n",
    "def get_keywords(model, num_topics=-1, num_words=5):\n",
    "    topic_vectors = model.show_topics(num_topics=num_topics, num_words=num_words, formatted=False)\n",
    "    return sorted(tuple(set([w[0] for t in topic_vectors for w in t[1]])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data recovery\n",
    "\n",
    "We download the labeled data from the Google Sheet.\n",
    "This data can also be obtained from a local spreadsheet file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# access the sheets and get the commit sheet\n",
    "gc = pygsheets.authorize(service_file='< JSON file with credentials for Google API >')\n",
    "sheets = gc.open_by_url(\"< URL of your Google Sheet >\")\n",
    "commit_sheet = sheets[0]  # Specific sheet of your Google Sheet\n",
    "\n",
    "# get a dictionary of the tables\n",
    "data_dic = commit_sheet.get_all_records()\n",
    "\n",
    "pandas_df = pd.DataFrame(data=data_dic)\n",
    "new_df = pandas_df[pandas_df[\"Labels\"].str.contains(\"cost-\")]\n",
    "new_df  # Pandas dataframe with cost-related entries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparing Commit corpus\n",
    "\n",
    "All the commit messages are fetched and pre-processed for the topic modelers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "commit_array = []\n",
    "for idx, item in new_df.iterrows():\n",
    "    commit_array.append(item['Commit Description'])\n",
    "commit_corpus = prepare_corpus(commit_array)\n",
    "(commit_corpus_dict, commit_corpus_bow, commit_tfidf_model) = build_tfidf_model(commit_corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Topic Modeling\n",
    "\n",
    "All three topic modelers are run independently and their results are intersected in a single list."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "commit_lsi_model = LsiModel(commit_tfidf_model[commit_corpus_bow], id2word=commit_corpus_dict, num_topics=100, onepass=False)\n",
    "commit_lda_model = LdaModel(commit_corpus_bow, id2word=commit_corpus_dict, num_topics=100)\n",
    "commit_hdp_model = HdpModel(commit_corpus_bow, id2word=commit_corpus_dict)\n",
    "\n",
    "# extract the common keywords among the three models (top 10 topic vectors)\n",
    "commit_topics = set(get_keywords(commit_lsi_model, num_topics=100))\\\n",
    "    .intersection(set(get_keywords(commit_lda_model, num_topics=100)))\\\n",
    "    .intersection(set(get_keywords(commit_hdp_model, num_topics=100)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Presenting results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "commit_topics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization of results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "topics = commit_lsi_model.show_topics(formatted=False, num_topics=-1, num_words=10)\n",
    "data_flat = [w for w_list in commit_corpus for w in w_list]\n",
    "counter = Counter(data_flat)\n",
    "\n",
    "out = []\n",
    "for i, topic in topics:\n",
    "    for word, weight in topic:\n",
    "        out.append([word, i , weight, counter[word]])\n",
    "\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])\n",
    "\n",
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16,10), sharey=True, dpi=160)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
    "    ax.set_ylabel('Word Count', color=cols[i], fontsize=16)\n",
    "    ax_twin.set_ylim(-1.25, 1.25); ax.set_ylim(-500, 500)\n",
    "    ax.set_title('Topic ' + str(i+1), color=cols[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right', fontsize=16)\n",
    "    ax.legend(loc='upper left', fontsize=12); ax_twin.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "fig.tight_layout(w_pad=2)\n",
    "fig.suptitle('Word Count and Importance of Topic Keywords for LSI in commits', fontsize=22, y=1.05)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure().clear()\n",
    "topics = commit_lda_model.show_topics(formatted=False, num_topics=-1, num_words=10)\n",
    "data_flat = [w for w_list in commit_corpus for w in w_list]\n",
    "counter = Counter(data_flat)\n",
    "\n",
    "out = []\n",
    "for i, topic in topics:\n",
    "    for word, weight in topic:\n",
    "        out.append([word, i , weight, counter[word]])\n",
    "\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])\n",
    "df.sort_values(by=['topic_id'])\n",
    "\n",
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16,10), sharey=True, dpi=160)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
    "    ax.set_ylabel('Word Count', color=cols[i], fontsize=16)\n",
    "    ax_twin.set_ylim(0, 0.085); ax.set_ylim(0, 500)\n",
    "    ax.set_title('Topic ' + str(i+1), color=cols[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right', fontsize=16)\n",
    "    ax.legend(loc='upper left', fontsize=12); ax_twin.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "fig.tight_layout(w_pad=2)\n",
    "fig.suptitle('Word Count and Importance of Topic Keywords for LDA in commits', fontsize=22, y=1.05)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure().clear()\n",
    "topics = commit_hdp_model.show_topics(num_words=10, formatted=False)\n",
    "data_flat = [w for w_list in commit_corpus for w in w_list]\n",
    "counter = Counter(data_flat)\n",
    "\n",
    "out = []\n",
    "for i, topic in topics:\n",
    "    for word, weight in topic:\n",
    "        out.append([word, i , weight, counter[word]])\n",
    "\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])\n",
    "\n",
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16,10), sharey=True, dpi=160)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
    "    ax.set_ylabel('Word Count', color=cols[i], fontsize=16)\n",
    "    ax_twin.set_ylim(0, 0.005); ax.set_ylim(0, 150)\n",
    "    ax.set_title('Topic ' + str(i+1), color=cols[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right', fontsize=16)\n",
    "    ax.legend(loc='upper left', fontsize=12); ax_twin.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "fig.tight_layout(w_pad=2)\n",
    "fig.suptitle('Word Count and Importance of Topic Keywords for HDP in commits', fontsize=22, y=1.05)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}